# Crivo de Erat√≥stenes - Implementa√ß√£o Distribu√≠da

Implementa√ß√£o paralela do algoritmo Crivo de Erat√≥stenes usando MPI (Message Passing Interface) para encontrar n√∫meros primos de forma eficiente.

## üìã Descri√ß√£o

Este projeto cont√©m duas implementa√ß√µes do Crivo de Erat√≥stenes:

- **Singular**: vers√£o sequencial cl√°ssica para benchmark
- **Distribu√≠do**: vers√£o paralela usando MPI que distribui o trabalho entre m√∫ltiplos processos

### Algoritmo

O Crivo de Erat√≥stenes √© um algoritmo eficiente para encontrar todos os n√∫meros primos at√© um valor N:

1. **Fase sequencial (rank 0)**: calcula os "primos base" at√© ‚àöN usando o crivo cl√°ssico
2. **Broadcast**: distribui os primos base para todos os processos via `MPI_Bcast`
3. **Fase paralela**: cada processo marca compostos em sua fatia do intervalo [2, N]
4. **Redu√ß√£o**: agrega contagens e listas de primos encontrados

#### Por que p¬≤ ?

O algoritmo usa `p*p` como ponto de partida porque:
- M√∫ltiplos menores (2p, 3p, ..., (p-1)p) j√° foram eliminados por primos anteriores
- S√≥ √© necess√°rio testar primos at√© ‚àöN para eliminar todos os compostos at√© N
- A condi√ß√£o `p*p <= limite` √© equivalente a `p <= ‚àölimite` sem calcular raiz quadrada a cada itera√ß√£o

## üõ†Ô∏è Requisitos

- **Compilador C++11** ou superior
- **MPI** (OpenMPI ou MPICH)
- **Make**

### Instala√ß√£o das depend√™ncias (Ubuntu/Debian)

```bash
sudo apt-get update
sudo apt-get install build-essential libopenmpi-dev openmpi-bin
```

## üöÄ Compila√ß√£o

```bash
# Compilar ambas as vers√µes
make

# Compilar apenas a vers√£o singular
make singular

# Compilar apenas a vers√£o distribu√≠da
make distribuido

# Limpar execut√°veis
make clean
```

## üìñ Uso

### Vers√£o Singular

```bash
./singular <qtd> <t1> [t2 ...]
```

**Exemplo:**
```bash
./singular 3 100 1000 10000
```

**Sa√≠da:**
```
CRIVO DE ERAT√ìSTENES - SINGULAR
Tamanhos: 100 1000 10000 

Tamanho 100: 25 primos em 0.000023 s
Tamanho 1000: 168 primos em 0.000145 s
Tamanho 10000: 1229 primos em 0.001834 s
```

### Vers√£o Distribu√≠da

```bash
mpirun -np <num_processos> ./distribuido <qtd> <t1> [t2 ...]
```

**Exemplos:**

```bash
# Com 4 processos
mpirun -np 4 ./distribuido 3 100 1000 10000

# Com 8 processos para tamanhos maiores
mpirun -np 8 ./distribuido 2 1000000 10000000
```

**Sa√≠da:**
```
Tamanho 100: 25 primos, MediaTotal=0.000234s MediaParal=0.000089s MediaSeq=0.000012s
Tamanho 1000: 168 primos, MediaTotal=0.000456s MediaParal=0.000234s MediaSeq=0.000034s
Tamanho 10000: 1229 primos, MediaTotal=0.002134s MediaParal=0.001456s MediaSeq=0.000089s
```

### Par√¢metros

- `<qtd>`: quantidade de tamanhos a testar
- `<t1> [t2 ...]`: valores de N (limite superior para buscar primos)

## üìä Estrutura do C√≥digo

### `singular.cpp`

Implementa√ß√£o sequencial simples:
- Usa `vector<char>` para marcar primos
- Mede tempos total, sequencial e paraleliz√°vel
- Retorna lista completa de primos encontrados

### `distribuido.cpp`

Implementa√ß√£o paralela com MPI:

#### Estrutura `Medicao`
```cpp
struct Medicao {
    long long tempoTotal;
    long long tempoParalelizavel;
    long long tempoSequencial;
    int quantidadePrimos;
    vector<int> primos;
    int numProcessos;
};
```

#### Fun√ß√£o `crivoDeEratostenes(int n)`

1. **Gera√ß√£o dos primos base (rank 0)**
   ```cpp
   int limite = (int)floor(sqrt((double)n + 1.0));
   // Crivo cl√°ssico at√© limite
   ```

2. **Broadcast dos primos base**
   ```cpp
   MPI_Bcast(&tamPrimosBase, 1, MPI_INT, 0, MPI_COMM_WORLD);
   MPI_Bcast(primosBase.data(), tamPrimosBase, MPI_INT, 0, MPI_COMM_WORLD);
   ```

3. **Particionamento do trabalho**
   ```cpp
   long long chunk = (total_numbers + size - 1) / size;
   long long inicio_local = start_index + rank * chunk;
   long long fim_local = min(inicio_local + chunk, end_index + 1LL);
   ```

4. **Marca√ß√£o local de compostos**
   ```cpp
   for (int primo : primosBase) {
       long long start = max((long long)p*p,
                             ((inicio_local + p - 1) / p) * p);
       for (long long i = start; i < fim_local; i += p)
           isPrimo_local[i - inicio_local] = false;
   }
   ```

5. **Agrega√ß√£o dos resultados**
   ```cpp
   MPI_Reduce(&primos_locais, &total_primos, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);
   MPI_Gatherv(...);  // Coleta as listas de primos
   ```

## üéØ Medi√ß√µes de Desempenho

A vers√£o distribu√≠da realiza 5 medi√ß√µes para cada tamanho e calcula as m√©dias:

- **MediaTotal**: tempo total de execu√ß√£o (incluindo comunica√ß√£o MPI)
- **MediaParal**: tempo da fase paraleliz√°vel (marca√ß√£o de compostos)
- **MediaSeq**: tempo da fase sequencial (gera√ß√£o dos primos base)

## üîç Exemplos de Uso Avan√ßado

### Teste de escalabilidade

```bash
# Testar com diferentes n√∫meros de processos
for np in 1 2 4 8 16; do
    echo "=== $np processos ==="
    mpirun -np $np ./distribuido 1 10000000
done
```

### Teste de tamanhos crescentes

```bash
mpirun -np 8 ./distribuido 5 100000 500000 1000000 5000000 10000000
```

## üìù Detalhes de Implementa√ß√£o

### Otimiza√ß√µes

- **vector<char>** em vez de `vector<bool>` para melhor desempenho
- Coleta de primos apenas para N ‚â§ 10000 (evita overhead de mem√≥ria)
- Uso de `long long` para suportar valores grandes de N
- C√°lculo eficiente do primeiro m√∫ltiplo: `((inicio_local + p - 1) / p) * p`

### Comunica√ß√£o MPI

- **MPI_Bcast**: distribui primos base e par√¢metros
- **MPI_Reduce**: soma contagens (MPI_SUM) e encontra tempos m√°ximos (MPI_MAX)
- **MPI_Gather/Gatherv**: coleta listas de primos de todos os processos
- **MPI_Barrier**: sincroniza antes de finalizar

## üêõ Tratamento de Erros

- Valida√ß√£o de argumentos no rank 0
- `MPI_Abort` para erros fatais
- Guards para evitar acesso fora dos limites (`limite >= 0`, `limite >= 1`)

## üìö Refer√™ncias

- [Crivo de Erat√≥stenes - Wikipedia](https://pt.wikipedia.org/wiki/Crivo_de_Erat√≥stenes)
- [MPI Documentation](https://www.open-mpi.org/doc/)
- [Tutorial MPI](https://mpitutorial.com/)

## üë• Autor

Eros Lunardon, Victor Vechi, Igor Souza

## üìÑ Licen√ßa

Este projeto est√° sob licen√ßa aberta para fins educacionais.
